"""
Main scraper for GM Collin and YK Canada store locators.
Focused implementation using exact selectors.
"""

import time
import os
from typing import List, Dict, Any
from datetime import datetime
from scraper_factory import ScraperFactory


class MainScraper:
    """Main scraper for Canadian store locators."""
    
    def __init__(self):
        """Initialize with GM Collin and YK Canada websites."""
        self.websites_to_scrape = [
            "gmcollin.ca",
            "ykcanada.com".  # add any new target websites here
        ]
        self.results = []
        self.factory = ScraperFactory()
        
        # Ensure output directory exists
        os.makedirs('output', exist_ok=True)
    
    def scrape_website(self, website_identifier: str) -> Dict[str, Any]:
        """Scrape a single website."""
        print(f"\n{'='*60}")
        print(f"ğŸŒ Processing website: {website_identifier}")
        print(f"{'='*60}")
        
        start_time = datetime.now()
        
        try:
            scraper = self.factory.create_scraper(website_identifier)
            
            if not scraper:
                return {
                    "website": website_identifier,
                    "status": "failed",
                    "error": f"No scraper available for {website_identifier}",
                    "duration": 0,
                    "locations_found": 0,
                    "output_file": None
                }
            
            print(f"âœ… Found scraper: {scraper.__class__.__name__}")
            
            # Run the scraper
            summary = scraper.run()
            
            # Calculate duration
            duration = (datetime.now() - start_time).total_seconds()
            
            result = {
                "website": website_identifier,
                "status": "success",
                "error": None,
                "duration": duration,
                "locations_found": summary.get("total_locations", 0),
                "output_file": summary.get("output_file"),
                "scraper_class": scraper.__class__.__name__
            }
            
            print(f"\nâœ… Successfully scraped {website_identifier}")
            print(f"   ğŸ“Š Locations found: {result['locations_found']}")
            print(f"   ğŸ“ Output file: {result['output_file']}")
            print(f"   â±ï¸ Duration: {duration:.2f} seconds")
            
            return result
            
        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()
            
            print(f"\nâŒ Failed to scrape {website_identifier}")
            print(f"   Error: {e}")
            
            return {
                "website": website_identifier,
                "status": "failed",
                "error": str(e),
                "duration": duration,
                "locations_found": 0,
                "output_file": None
            }
    
    def run_all_scrapers(self) -> List[Dict[str, Any]]:
        """Run scrapers for all websites."""
        print("ğŸ Canadian Store Locator Scraper")
        print("=" * 50)
        print("ğŸ¯ Focused on: GM Collin & YK Canada")
        print("ğŸ”§ Using exact selectors (no fallbacks)")
        print(f"ğŸ“ Output files will be saved in: ./output/")
        
        overall_start_time = datetime.now()
        
        for idx, website in enumerate(self.websites_to_scrape, 1):
            print(f"\nğŸ“ Processing {idx}/{len(self.websites_to_scrape)}: {website}")
            
            result = self.scrape_website(website)
            # here go throw the result and find the phone number and the websites and reviews if possible.
            self.results.append(result)
            
            # Add delay between websites
            if idx < len(self.websites_to_scrape):
                print("â³ Waiting 3 seconds before next website...")
                time.sleep(3)
        
        # Print summary
        total_duration = (datetime.now() - overall_start_time).total_seconds()
        self.print_summary(total_duration)
        
        return self.results
    
    def print_summary(self, total_duration: float) -> None:
        """Print final summary."""
        print(f"\n{'='*60}")
        print("ğŸ“Š SCRAPING SUMMARY")
        print(f"{'='*60}")
        
        successful = [r for r in self.results if r["status"] == "success"]
        failed = [r for r in self.results if r["status"] == "failed"]
        total_locations = sum(r["locations_found"] for r in self.results)
        
        print(f"ğŸŒ Websites processed: {len(self.results)}")
        print(f"âœ… Successful: {len(successful)}")
        print(f"âŒ Failed: {len(failed)}")
        print(f"ğŸ“ Total locations found: {total_locations}")
        print(f"â±ï¸ Total duration: {total_duration:.2f} seconds")
        print(f"ğŸ“ Output directory: ./output/")
        
        if successful:
            print(f"\nâœ… Successful websites:")
            for result in successful:
                print(f"   - {result['website']}: {result['locations_found']} locations â†’ {result['output_file']}")
        
        if failed:
            print(f"\nâŒ Failed websites:")
            for result in failed:
                print(f"   - {result['website']}: {result['error']}")
        
        print(f"\nğŸ‰ Scraping completed!")


def main():
    """Main execution function."""
    scraper = MainScraper()
    return scraper.run_all_scrapers()


if __name__ == "__main__":
    main()